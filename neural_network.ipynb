{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926553b8",
   "metadata": {},
   "source": [
    "# Neural network for my thesis that's taken a year when it should have taken a month \n",
    "\n",
    "For fuck's sake that's probably the easiest project I've ever done, what the fuck Marina. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d11e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improrts \n",
    "\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7cf812",
   "metadata": {},
   "source": [
    "## Probably should do some preprocessing \n",
    "\n",
    "Yet again, but it's just some scaling and shit \n",
    "\n",
    "Also maybe check your data in general to fix any issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "\n",
    "column_names = ['duration', 'RMSSD', 'pNN50', 'HF', 'LF', 'HF/LF', 'MET', 'temperature', 'thermal_comfort']\n",
    "\n",
    "df = pd.read_csv('processed_data.csv', names = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some scaling i guess \n",
    "#scale temperature and hrv? since freequency is on normal units, scale only rmssd\n",
    "#here i am scaling RMSSD only since I have no temperature data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['RMSSD']] = scaler.fit_transform(df[['RMSSD']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fde0c",
   "metadata": {},
   "source": [
    "## Then just do a classifier because thermal comfort very conveniently comes in a scale\n",
    "\n",
    "I mean, I think so. Softmax?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you already have done a classifier so maybe copy that and finish? \n",
    "\n",
    "#this is the network without being actually shaped to the imports we're doing \n",
    "\n",
    "num_features = 9 #amount of features on import \n",
    "num_classes = 3 #amount of classes on output, doing classification\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape = (num_features,)),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'), \n",
    "    layers.Dense(16, activation = 'relu'),\n",
    "    layers.Dense(num_classes, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#gurl now just gather the data, fit and train the network, check it and then maybe do the fanger ig? also, maybe contact the people you need to? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we should be fitting the network \n",
    "\n",
    "#split the dataset into train and test, \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=, random_state= )\n",
    "\n",
    "#fit model\n",
    "#model.fit(X_train, y_train, batch_size=, epochs= )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
