{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb62b8f3",
   "metadata": {},
   "source": [
    "# Data analysis for HRV and MET\n",
    "\n",
    "Processing data received through MAXIM REFDES103 to use in training neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79646c75",
   "metadata": {},
   "source": [
    "## Imports and system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf1f1a",
   "metadata": {},
   "source": [
    "### Imports for the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3371543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from statistics import mean\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.interpolate import CubicSpline\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63117c5",
   "metadata": {},
   "source": [
    "### Data extraction through dataframe for the whole file\n",
    "\n",
    "Plus, some plots to be able to see what's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da51356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot(df): \n",
    "\n",
    "    #get timestamps\n",
    "    timestamp = df['sample_time']\n",
    "\n",
    "    #get rr intervals \n",
    "    rr = df['rr']\n",
    "    rr_unprocessed = rr.to_numpy()\n",
    "\n",
    "    #get magnitude of PPG measurement\n",
    "    amp = df['green']\n",
    "    amp_array = amp.to_numpy()\n",
    "\n",
    "    max = np.max(amp_array)\n",
    "    min = np.min(amp_array)\n",
    "\n",
    "    amp_array_norm = (amp_array - min) / (max - min)\n",
    "\n",
    "    #get synthetic acceleration \n",
    "    acx = df['acceleration_x']\n",
    "    acy = df['acceleration_y']\n",
    "    acz = df['acceleration_z']\n",
    "\n",
    "    syn_ac = np.square(acx) + np.square(acy) + np.square(acz)\n",
    "    syn_ac = np.power(syn_ac, 1/2)\n",
    "\n",
    "    #get rr without zeroes\n",
    "    rr_nz = rr[rr!=0]\n",
    "    rr_array = rr_nz.to_numpy()\n",
    "\n",
    "    #get calories\n",
    "    cal = df['calorie']\n",
    "\n",
    "    #plot data\n",
    "    figure, axis = plt.subplots(3)\n",
    "    axis[0].plot(timestamp, amp_array_norm)\n",
    "    axis[1].plot(timestamp, rr)\n",
    "    axis[2].plot(timestamp, syn_ac)\n",
    "\n",
    "    return timestamp, amp_array_norm, rr_unprocessed, rr_array, syn_ac, cal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bf104",
   "metadata": {},
   "source": [
    "## HRV analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba23a77",
   "metadata": {},
   "source": [
    "### Denoising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b11b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(rr_array): \n",
    "\n",
    "    #denoising through IQR \n",
    "    Q1 = np.percentile(rr_array, 25)\n",
    "    Q3 = np.percentile(rr_array, 75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    iqr_min = Q1 - 1.5*IQR\n",
    "    iqr_max = Q3 + 1.5*IQR\n",
    "\n",
    "    rr_array_clean = rr_array[(rr_array <iqr_max) & (rr_array>iqr_min)]\n",
    "\n",
    "    return rr_array_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa7b1d",
   "metadata": {},
   "source": [
    "### Time analysis methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f4fae",
   "metadata": {},
   "source": [
    "#### RMSSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSSD_func(rr_array): \n",
    "\n",
    "    itersize = rr_array.size\n",
    "    squares = 0\n",
    "\n",
    "    for i in range(itersize-2) : \n",
    "        squares += np.square(rr_array[i+1] - rr_array[i])\n",
    "\n",
    "    average = squares / (itersize-1)\n",
    "\n",
    "    RMSSD = np.power(average, 1/2)\n",
    "    \n",
    "    return RMSSD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983cf0fe",
   "metadata": {},
   "source": [
    "#### pNN50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN50count(data_array): \n",
    "\n",
    "    NN50count = 0\n",
    "    for i in range(data_array.size - 1):\n",
    "        if np.abs(data_array[i+1]-data_array[i]) > 50: \n",
    "            NN50count += 1     \n",
    "\n",
    "    pNN50 = NN50count/data_array.size\n",
    "    return pNN50\n",
    "\n",
    "def windowing(time_array, start, finish): \n",
    "\n",
    "    timer = start \n",
    "    counter = 0\n",
    "    new_start = 0\n",
    "    while ((time_array.iloc[timer] - time_array.iloc[start]).seconds<120): \n",
    "        counter += 1\n",
    "        timer = start + counter\n",
    "        if (time_array.iloc[timer] - time_array.iloc[start]).seconds == 30: \n",
    "            new_start = timer\n",
    "        if (time_array.iloc[timer] == time_array.iloc[-1]): \n",
    "            finish = True\n",
    "            break\n",
    "    end = timer\n",
    "\n",
    "    return end, new_start, finish\n",
    "\n",
    "def pNN50(time_array, rr_array):\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    percs = []\n",
    "    new_start = 0\n",
    "    finish = False\n",
    "\n",
    "    while (time_array.iloc[end] <= time_array.iloc[-1]):\n",
    "        end, new_start, finish = windowing(time_array, start, finish)\n",
    "        if finish: \n",
    "            break\n",
    "        count_array = rr_array[start:end]\n",
    "        pNN50 = NN50count(count_array)\n",
    "        percs.append(pNN50)\n",
    "        start = new_start\n",
    "        \n",
    "\n",
    "    return percs\n",
    "\n",
    "def return_pNN50(timestamp, rr_unprocessed): \n",
    "\n",
    "    time = pd.to_datetime(timestamp)\n",
    "\n",
    "    #percentages = pNN50(time)\n",
    "    percentages = pNN50(time, rr_unprocessed)\n",
    "    if len(percentages) == 0: \n",
    "        pNN50_total = None\n",
    "\n",
    "    pNN50_total = mean(percentages)\n",
    "\n",
    "    return pNN50_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d191d",
   "metadata": {},
   "source": [
    "### Frequency analysis methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c7599",
   "metadata": {},
   "source": [
    "#### FTT with interpolation \n",
    "\n",
    "This one like pNN50 also needs to be edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4359a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(rr_array_clean, axis): \n",
    "\n",
    "    #get a time array for plotting\n",
    "    time_size = rr_array_clean.size\n",
    "    times = np.empty(time_size, dtype = int)\n",
    "\n",
    "    for i in range(time_size): \n",
    "        times[i] = i\n",
    "\n",
    "    #make a uniform time array \n",
    "    fs = 25 \n",
    "    uniform_times = np.arange(0, time_size, 1/fs)\n",
    "\n",
    "    #do cubic spline\n",
    "    cs = CubicSpline(times, rr_array_clean)\n",
    "    interpolated_rr = cs(uniform_times) \n",
    "\n",
    "    axis[0].plot(uniform_times, interpolated_rr)\n",
    "\n",
    "    return interpolated_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aeda02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT (interpolated_rr, axis): \n",
    "\n",
    "    fs = 25\n",
    "    n = interpolated_rr.size\n",
    "\n",
    "    interpolated_rr = interpolated_rr - np.mean(interpolated_rr) #remove DC \n",
    "\n",
    "    rfft_array = rfft(interpolated_rr)\n",
    "    rfftfreq_array = rfftfreq(n, 1/fs)\n",
    "\n",
    "    axis[1].plot(rfftfreq_array, np.abs(rfft_array))\n",
    "\n",
    "    return rfft_array, rfftfreq_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_anal(rr_array_clean): \n",
    "\n",
    "    figure, axis = plt.subplots(3)\n",
    "\n",
    "    interpolated_rr = interpolation(rr_array_clean, axis)\n",
    "    [rfft, rfftfreq] = FFT(interpolated_rr, axis)\n",
    "\n",
    "    #gets and plots the power of spectrum\n",
    "    mag = np.abs(rfft)\n",
    "    power = mag**2\n",
    "\n",
    "    axis[2].plot(rfftfreq, power)\n",
    "\n",
    "    #gets the HF, LF, HF/LF parameters to be used in the neural network \n",
    "    lf_mask = (rfftfreq >= 0.04) & (rfftfreq <= 0.15)\n",
    "    lf_power = np.trapz(power[lf_mask], rfftfreq[lf_mask])\n",
    "\n",
    "    hf_mask = (rfftfreq >= 0.15) & (rfftfreq <= 0.4)\n",
    "    hf_power = np.trapz(power[hf_mask], rfftfreq[hf_mask])\n",
    "\n",
    "    total_power = lf_power + hf_power \n",
    "    lf_nu = lf_power/total_power\n",
    "    hf_nu = hf_power/total_power\n",
    "    ratio = hf_nu/lf_nu\n",
    "\n",
    "\n",
    "    return lf_nu, hf_nu, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3bb43",
   "metadata": {},
   "source": [
    "## MET analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672b76c",
   "metadata": {},
   "source": [
    "### Caloric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2df7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MET(timestamp, cal): \n",
    "\n",
    "    #MET = cal / (kg * hours)\n",
    "    kg =  64\n",
    "    time_size = timestamp.size\n",
    "\n",
    "    #get calories\n",
    "    cal_size = cal.size \n",
    "    calories = cal[cal_size-1]\n",
    "\n",
    "    #get duration of exercise in hours\n",
    "    t1 = pd.to_datetime(timestamp[0])\n",
    "    t2 = pd.to_datetime(timestamp[time_size-1])\n",
    "    duration = (t2-t1).seconds/(60*60)\n",
    "\n",
    "    #calculate MET\n",
    "    total_MET = calories / (kg*duration)\n",
    "\n",
    "    return total_MET, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6556c",
   "metadata": {},
   "source": [
    "##  Gather all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_processing(df): \n",
    "\n",
    "    #get data\n",
    "    #df = pd.read_csv(\"001.csv\")\n",
    "    [timestamp, amp_array_norm, rr_unprocessed, rr_array, syn_ac, cal] = data_plot(df)\n",
    "    rr_array_clean = denoise(rr_array)\n",
    "\n",
    "    #time analysis measures\n",
    "    RMSSD = RMSSD_func(rr_array_clean)\n",
    "    pNN50 = return_pNN50(timestamp, rr_unprocessed)\n",
    "\n",
    "    #frequency analysis measures\n",
    "    [LF, HF, ratio] = freq_anal(rr_array_clean)\n",
    "\n",
    "    #MET\n",
    "    [total_MET, duration] = MET(timestamp, cal)\n",
    "\n",
    "    return duration, RMSSD, pNN50, HF, LF, ratio, total_MET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a303eb90",
   "metadata": {},
   "source": [
    "## Run file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(): \n",
    "\n",
    "    #iterate through folder of files\n",
    "    directory = \"./data_files\"\n",
    "\n",
    "    for name in os.listdir(directory):\n",
    "        \n",
    "        with open(os.path.join(directory, name)) as f: \n",
    "\n",
    "            df = pd.read_csv(f)\n",
    "            print(name)\n",
    "            \n",
    "            #get the data here to import right below\n",
    "            [duration, RMSSD, pNN50, HF, LF, ratio, total_MET] = run_processing(df)\n",
    "            data = [{\"duration\": duration, \"RMSSD\": RMSSD, \"pNN50\": pNN50, \"HF\": HF, \"LF\": LF, \"HF/LF\": ratio, \"MET\": total_MET, \"temperature\": 'None', \"thermal_comfort\": 'None' }]\n",
    "            \n",
    "            #import data into file of processed data\n",
    "            with open('processed_data.csv', 'a', newline = '') as csvfile:\n",
    "                fieldnames = ['duration', 'RMSSD', 'pNN50', 'HF', 'LF', 'HF/LF', 'MET', 'temperature', 'thermal_comfort']\n",
    "                writer = csv.DictWriter(csvfile, fieldnames= fieldnames)\n",
    "                writer.writerows(data)\n",
    "\n",
    "make_file()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
