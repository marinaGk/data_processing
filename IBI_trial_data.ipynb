{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis for HRV and MET received through device\n",
    "\n",
    "Using MAXIM maxref103 to receive data through bluetooth. \n",
    "\n",
    "Data received come in the format of raw PPG with peak detection and accelerometer with sampling of around 25 samples a second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "df = pd.read_csv(\"trial_HRM.csv\")\n",
    "#HRV_df = pd.read_csv(\"trial_HRV.csv\")\n",
    "\n",
    "#df = pd.read_csv(\"second_hrm_trial.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First get data through file received from device to analyze. Getting the PPG signal, the accelerometer signal to use for denoising and the RR interval signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#get magnitude of PPG measurement\n",
    "amp = df['green']\n",
    "amp_array = amp.to_numpy()\n",
    "\n",
    "samples = df['sample_count']\n",
    "rr = df['rr']\n",
    "timestamp = df['sample_time']\n",
    "\n",
    "#normalize\n",
    "max = np.max(amp_array)\n",
    "min = np.min(amp_array)\n",
    "\n",
    "amp_array_norm = (amp_array - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get synthetic acceleration \n",
    "acx = df['acceleration_x']\n",
    "acy = df['acceleration_y']\n",
    "acz = df['acceleration_z']\n",
    "\n",
    "syn_ac = np.square(acx) + np.square(acy) + np.square(acz)\n",
    "syn_ac = np.power(syn_ac, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rr and clean rr\n",
    "rr_nz = rr[rr!=0]\n",
    "rr_array = rr_nz.to_numpy()\n",
    "\n",
    "rr_array_no_dc = rr_array - np.mean(rr_array) #take out DC συνιστωσα\n",
    "\n",
    "#rr_array_clean = rr_array[(rr_array > 300) & (rr_array < 2000)] \n",
    "#rr_array_clean = rr_array_clean - np.mean(rr_array_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denoising by outlier detection and removal. Zero time data have already been removed from RR interval signal (since it is sampled at the same time as raw PPG)\n",
    "\n",
    "Remains to be done: try denoising by acceleration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do IQR on RR signal to remove outliers and clean rr\n",
    "import numpy as np\n",
    "\n",
    "Q1 = np.percentile(rr_array, 25)\n",
    "Q3 = np.percentile(rr_array, 75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print(IQR)\n",
    "\n",
    "iqr_min = Q1 - 1.5*IQR\n",
    "iqr_max = Q3 + 1.5*IQR\n",
    "\n",
    "print(iqr_min, iqr_max)\n",
    "\n",
    "rr_array_clean = rr_array[(rr_array <iqr_max) & (rr_array>iqr_min)]\n",
    "rr_array_clean = rr_array_clean - np.mean(rr_array_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting PPG, RR interval and acceleration signals to notice noise trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the PPG, RR, acc plot\n",
    "figure, axis = plt.subplots(3)\n",
    "axis[0].plot(timestamp, amp_array_norm)\n",
    "axis[1].plot(timestamp, rr)\n",
    "axis[2].plot(timestamp, syn_ac)\n",
    "\n",
    "#rr plot seems to follow the direction of PPG measurement as opposed to acceleration which appears to be random here making everything a bit complicated "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSSD \n",
    "\n",
    "method that calculates differences between successive IBIs \n",
    "then squares them \n",
    "then averages all of the results \n",
    "and then takes square root \n",
    "\n",
    "WHICH IS EASY TO DEVELOP ON YOUR OWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#RMSSD \n",
    "#removing all zero values to get only actual IBIs\n",
    "rr_nz = rr[rr!=0]\n",
    "\n",
    "#RMSSD: root mean square of successive differences\n",
    "#turn this into a function at some point \n",
    "rr_nz_array = rr_nz.to_numpy() #float64 \n",
    "\n",
    "itersize = rr_nz_array.size\n",
    "squares = 0\n",
    "\n",
    "for i in range(itersize-2) : \n",
    "    squares += np.square(rr_nz_array[i+1] - rr_nz_array[i])\n",
    "\n",
    "average = squares / (itersize-1)\n",
    "\n",
    "RMSSD = np.power(average, 1/2)\n",
    "\n",
    "print(RMSSD)\n",
    "\n",
    "#you get RMSSD here but you need to use that later to compare between different samples\n",
    "#turn it into a function to use whenever \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPECTRAL ANALYSIS\n",
    "\n",
    "Doing an FFT. Now, supposedly, I should be seeing something here like an HF and LF component but I'm not. Which means something is wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.fft import fft, fftfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT without interpolation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is FFT without interpolation that works to actually denoise the signal\n",
    "n = rr_array_no_dc.size\n",
    "fs = 25\n",
    "\n",
    "fft = fft(rr_array_no_dc)\n",
    "fftfreq = fftfreq(n, 1/fs)\n",
    "\n",
    "rfft = rfft(rr_array_no_dc)\n",
    "rfftfreq = rfftfreq(n, 1/fs) #right side FFT for only not imaginary numbers (can't recall how those are called but basically magnitude)\n",
    "\n",
    "#plt.plot(fftfreq, np.abs(fft))\n",
    "plt.plot(rfftfreq, np.abs(rfft)) \n",
    "\n",
    "#data here is not interpolated - due to irrgularity FFT will not show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT with interpolation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you need to do Lagrange interpolation on your RR data and autoregressive model for analysis\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "time_size = rr_array_no_dc.size\n",
    "times = np.empty(time_size, dtype = int)\n",
    "\n",
    "#do cubic spline interpolation which is better suited for HRV\n",
    "for i in range(time_size): \n",
    "    times[i] = i\n",
    "cs = CubicSpline(times, rr_array_no_dc)\n",
    "\n",
    "uniform_times = np.arange(0, time_size, 1/fs) #make a uniform time array so as to also uniform the signal and then do FFT\n",
    "\n",
    "interpolated_rr = cs(uniform_times)\n",
    "\n",
    "plt.plot(uniform_times, interpolated_rr) #interpolated has negative times which MAKES NO SENSE GENERALLY SPEAKING\n",
    "\n",
    "#this makes IBI values turn negative which makes no sense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do FFT of RR signal received from device, interpolated but not otherwise denoised and probably a bit wrong and not smoothed at all\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "n = interpolated_rr.size\n",
    "fs = 25\n",
    "\n",
    "rfft = rfft(interpolated_rr)\n",
    "rfftfreq = rfftfreq(n, 1/fs)\n",
    "\n",
    "plt.plot(rfftfreq, np.abs(rfft)) \n",
    "plt.xlim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT with interpolation and clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "time_size = rr_array_clean.size\n",
    "times = np.empty(time_size, dtype = int)\n",
    "\n",
    "#do cubic spline interpolation which is better suited for HRV\n",
    "for i in range(time_size): \n",
    "    times[i] = i\n",
    "cs = CubicSpline(times, rr_array_clean)\n",
    "\n",
    "uniform_times = np.arange(0, time_size, 1/fs) #make a uniform time array so as to also uniform the signal and then do FFT\n",
    "\n",
    "interpolated_rr = cs(uniform_times)\n",
    "\n",
    "plt.plot(uniform_times, interpolated_rr) #interpolated has negative times which MAKES NO SENSE GENERALLY SPEAKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq\n",
    "n = interpolated_rr.size\n",
    "fs = 25\n",
    "\n",
    "rfft = rfft(interpolated_rr)\n",
    "rfftfreq = rfftfreq(n, 1/fs)\n",
    "\n",
    "plt.plot(rfftfreq, np.abs(rfft)) \n",
    "plt.xlim(0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so far we're facing the following problems: \n",
    "\n",
    "-without clean data we're taking no noise out - dealt with through outlier detection , also looking for acceleration methods\n",
    "-there's literally no smoothing - try autoregression\n",
    "-interpolation is always giving us negative values - no clue as to why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for the MET we mostly need to write down exactly how it is connected to acceleration which should not be that hard given that there's all those databases and papers but still gather some data. Here i'll be looking into how to get met through caloric count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left to be done: \n",
    "\n",
    "Try to denoise by using accelerometer. \n",
    "\n",
    "Figure out how to get MET through acceleration or calories burnt. \n",
    "\n",
    "Maybe do autoregression for smoothing. \n",
    "\n",
    "Move into writing the network and Fanger's model for comparison. \n",
    "\n",
    "Do more time-domain methods to train the network. \n",
    "\n",
    "Gather data (5 min intervals) and get results. \n",
    "\n",
    "Combine everything into one file and write experiment down. \n",
    "\n",
    "Write results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
